{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/annykay/NoiseInDataImpact/blob/main/DataPreprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cb4604ba",
      "metadata": {
        "id": "cb4604ba"
      },
      "source": [
        "# Data preprocessing\n",
        "<br>\n",
        "Data preparation (including feature selection and modification, outliers dropout, etc. as well as ML classification models' hyperparameters optimization) steps are presented here. The main goal of this section is to generate dataframes and optimal models that would be further used for noise introduction simulations.\n",
        "<br>\n",
        "<br>\n",
        "There are 4 different datasets and 5 ML models (DecisionTree, RandomForest, XGB, LogisticRegression, KNearestNeighbors)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1bf52f17",
      "metadata": {
        "id": "1bf52f17"
      },
      "outputs": [],
      "source": [
        "# Imports (ADD HERE IF STH NEEDED FOR YOU IS STILL ABSENT)\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.neighbors import LocalOutlierFactor, KNeighborsClassifier\n",
        "from sklearn.utils import resample\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.model_selection import GridSearchCV, train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2c5067dc",
      "metadata": {
        "id": "2c5067dc"
      },
      "source": [
        "### Stellar classification Dataset\n",
        "Source: https://www.kaggle.com/datasets/fedesoriano/stellar-classification-dataset-sdss17\n",
        "<br>\n",
        "Preparation pipeline is partially based on: https://www.kaggle.com/code/beyzanks/stellar-classification-98-4-acc-100-auc/notebook "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9c83b72b",
      "metadata": {
        "id": "9c83b72b"
      },
      "outputs": [],
      "source": [
        "# Loading the raw data and changing class labels to integers\n",
        "\n",
        "df = pd.read_csv(r'C:\\\\Users\\gangs\\Downloads\\star_classification.csv', engine='python')\n",
        "df[\"class\"]=[0 if i == \"GALAXY\" else 1 if i == \"STAR\" else 2 for i in df[\"class\"]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2c39433b",
      "metadata": {
        "id": "2c39433b"
      },
      "outputs": [],
      "source": [
        "# Deleting outliers\n",
        "\n",
        "clf = LocalOutlierFactor()\n",
        "y_pred = clf.fit_predict(df)\n",
        "x_score = clf.negative_outlier_factor_\n",
        "outlier_score = pd.DataFrame()\n",
        "outlier_score[\"score\"] = x_score\n",
        "threshold2 = -1.5                                            \n",
        "filtre2 = outlier_score[\"score\"] < threshold2\n",
        "outlier_index = outlier_score[filtre2].index.tolist()\n",
        "df.drop(outlier_index, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c156fb70",
      "metadata": {
        "id": "c156fb70"
      },
      "outputs": [],
      "source": [
        "# Deleting uncorrelated with target variable features\n",
        "\n",
        "df = df.drop(['obj_ID','alpha','delta','run_ID','rerun_ID','cam_col','field_ID','fiber_ID'], axis = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1ce83eeb",
      "metadata": {
        "id": "1ce83eeb"
      },
      "outputs": [],
      "source": [
        "# Downsampling of major class to make data balanced\n",
        "\n",
        "df_0 = df[df['class']==0]\n",
        "df_1 = df[df['class']==1]\n",
        "df_2 = df[df['class']==2]\n",
        "\n",
        "df_0_downsampled = resample(df_0, replace=False, n_samples=17000, random_state=123)\n",
        "df_downsampled = pd.concat([df_0_downsampled, df_1, df_2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "26c9f495",
      "metadata": {
        "id": "26c9f495"
      },
      "outputs": [],
      "source": [
        "stellar_x = df_downsampled.drop(['class'], axis = 1)\n",
        "stellar_y = df_downsampled.loc[:,'class'].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c8a79a1a",
      "metadata": {
        "id": "c8a79a1a"
      },
      "outputs": [],
      "source": [
        "# Data scaling and train-test splitting\n",
        "\n",
        "stellar_x = StandardScaler().fit_transform(stellar_x)\n",
        "X_train, X_test, y_train, y_test = train_test_split(stellar_x, stellar_y, test_size = 0.3, random_state = 123)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "88251c16",
      "metadata": {
        "id": "88251c16",
        "outputId": "ef385810-4f19-4884-947d-fee6805fea23"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RandomForestClassifier\n",
            "best parameters: {'max_depth': 14, 'n_estimators': 90}\n",
            "Train score: 0.9925838860437131\n",
            "Test score: 0.9770812928501469\n",
            "\n",
            "DecisionTree\n",
            "best parameters: {'max_depth': 9}\n",
            "Train score: 0.9817255757982817\n",
            "Test score: 0.9714005876591577\n",
            "\n",
            "KNearestNeigbors\n",
            "best parameters: {'n_neighbors': 3}\n",
            "Train score: 0.9650463157305572\n",
            "Test score: 0.9463271302644466\n",
            "\n",
            "XGBoostClassifier\n",
            "best parameters: {'learning_rate': 0.1, 'max_depth': 12, 'n_estimators': 100}\n",
            "Train score: 0.9993563372792656\n",
            "Test score: 0.9756447926869083\n",
            "\n",
            "Logisticregression\n",
            "best parameters: {'C': 2010}\n",
            "Train score: 0.9584417765091092\n",
            "Test score: 0.9598432908912831\n"
          ]
        }
      ],
      "source": [
        "# Models optimization\n",
        "\n",
        "RandomForest = GridSearchCV(\n",
        "    RandomForestClassifier(random_state=0),\n",
        "    {'max_depth': [i for i in range(12, 15)], 'n_estimators': [80, 90, 100]},\n",
        "    scoring = 'f1_micro',\n",
        "    cv = 3,\n",
        "    n_jobs=-1\n",
        ")\n",
        "RandomForest.fit(X_train, y_train)\n",
        "print('RandomForestClassifier\\nbest parameters:', RandomForest.best_params_)\n",
        "print('Train score: {}\\nTest score: {}'.format(\n",
        "    f1_score(y_train, RandomForest.predict(X_train), average='micro'),\n",
        "    f1_score(y_test, RandomForest.predict(X_test), average='micro')\n",
        "    )\n",
        ")\n",
        "\n",
        "DecisionTree = GridSearchCV(\n",
        "    DecisionTreeClassifier(random_state=0),\n",
        "    {'max_depth': [i for i in range(7, 11)]},\n",
        "    scoring = 'f1_micro',\n",
        "    cv = 3,\n",
        "    n_jobs=-1\n",
        ")\n",
        "DecisionTree.fit(X_train, y_train)\n",
        "print('\\nDecisionTree\\nbest parameters:', DecisionTree.best_params_)\n",
        "print('Train score: {}\\nTest score: {}'.format(\n",
        "    f1_score(y_train, DecisionTree.predict(X_train), average='micro'),\n",
        "    f1_score(y_test, DecisionTree.predict(X_test), average='micro')\n",
        "    )\n",
        ")\n",
        "\n",
        "KNN = GridSearchCV(\n",
        "    KNeighborsClassifier(),\n",
        "    {'n_neighbors': [i for i in range(1, 5)]},\n",
        "    scoring = 'f1_micro',\n",
        "    cv = 3,\n",
        "    n_jobs=-1\n",
        ")\n",
        "KNN.fit(X_train, y_train)\n",
        "print('\\nKNearestNeigbors\\nbest parameters:', KNN.best_params_)\n",
        "print('Train score: {}\\nTest score: {}'.format(\n",
        "    f1_score(y_train, KNN.predict(X_train), average='micro'),\n",
        "    f1_score(y_test, KNN.predict(X_test), average='micro')\n",
        "    )\n",
        ")\n",
        "\n",
        "XGB = GridSearchCV(\n",
        "    XGBClassifier(random_state=0),\n",
        "    {'max_depth': [15, 10, 12], 'n_estimators': [100, 80, 120], 'learning_rate': [0.1, 0.2, 0.05]},\n",
        "    cv = 3,\n",
        "    scoring='f1_micro',\n",
        "    n_jobs=-1\n",
        ")\n",
        "XGB.fit(X_train, y_train)\n",
        "print('\\nXGBoostClassifier\\nbest parameters:', XGB.best_params_)\n",
        "print('Train score: {}\\nTest score: {}'.format(\n",
        "    f1_score(y_train, XGB.predict(X_train), average='micro'),\n",
        "    f1_score(y_test, XGB.predict(X_test), average='micro')\n",
        "    )\n",
        ")\n",
        "\n",
        "LogReg = GridSearchCV(\n",
        "    LogisticRegression(random_state=0, max_iter=1000),\n",
        "    {'C': np.arange(1900, 2200, 10)},\n",
        "    cv = 3,\n",
        "    scoring='f1_micro',\n",
        "    n_jobs=-1\n",
        ")\n",
        "LogReg.fit(X_train, y_train)\n",
        "print('\\nLogisticregression\\nbest parameters:', LogReg.best_params_)\n",
        "print('Train score: {}\\nTest score: {}'.format(\n",
        "    f1_score(y_train, LogReg.predict(X_train), average='micro'),\n",
        "    f1_score(y_test, LogReg.predict(X_test), average='micro')\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "942c1a5a",
      "metadata": {
        "id": "942c1a5a"
      },
      "outputs": [],
      "source": [
        "print('kek')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "name": "DataPreprocessing.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}